# gcp-data-streaming-project
Real-time Data Processing in GCP using Kafka, Spark structured streaming and a few more

## Project 1 â€“ Real time data steam pipeline.
In this project, we have a data source that streams activities of a retail business website. We will complete the following task below:

Ingest streaming data into Data warehouse in GCP.
Get the total number of products added to cart in real time.
Get the most visited category/sub-category and update the Data warehouse accordingly (Every 5 minutes). 

Note: All tasks will be completed in real-time and sent to one table in the Data warehouse every 5 minutes.

Project workflow is illustrated below.

![Data-streaming-pipeline](https://user-images.githubusercontent.com/71997016/156401410-c52e8435-97c6-4d2e-8fa9-ef2a387ccaa2.png)
