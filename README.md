# gcp-data-streaming-project
Real-time Data Processing in GCP using Kafka, Spark structured streaming and a few more

## Project 1 â€“ Real time data steam pipeline.
In this project, we have a data source that streams activities of a retail business website. We will complete the following task below:

Ingest streaming data into Data warehouse in GCP.
Get the total number of products added to cart in real time.
Get the most visited category/sub-category and update the Data warehouse accordingly (Every 5 minutes). 

Note: All tasks will be completed in real-time and sent to one table in the Data warehouse every 5 minutes.

Project workflow is illustrated below.

![Data-streaming-pipeline](https://user-images.githubusercontent.com/71997016/156413698-eefc2db8-a9af-4723-8597-75cda50998fd.png)

